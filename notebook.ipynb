{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5886f4c3-b505-49c9-b2fa-64eccfa80313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from utils.preprocess import prepare_document\n",
    "from utils.universal_parser import parse_cv_text, extract_requirements\n",
    "from utils.matcher import rule_based_score\n",
    "from utils.decision import make_decision, save_results_to_csv\n",
    "from utils.sentiment import classify_sentiment\n",
    "from utils.embedding import compute_similarity\n",
    "from utils.rl_agent import SimpleRLAgent\n",
    "\n",
    "# Matplotlib style\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03024e8-fdbe-4963-b777-7ef80b8b168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 CV PDF files.\n",
      "Sample parsed CV data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'filename': 'cv1.pdf.pdf',\n",
       " 'domain': 'IT',\n",
       " 'degree': 'BTECH',\n",
       " 'skills': ['data analysis',\n",
       "  'deep learning',\n",
       "  'financial analysis',\n",
       "  'machine learning',\n",
       "  'numpy',\n",
       "  'pandas',\n",
       "  'python',\n",
       "  'tensorflow'],\n",
       " 'experience': 0,\n",
       " 'text': 'talha usmani talhausmanigmailcom mumbai hehim profile computer science engineering graduate strong foundation programming software development proficient python practical experience gained internships academic projects passionate problemsolving building realworld tech solutions keen interest emerging technologies like machine learning actively seeking opportunities contribute grow dynamic innovationdriven environment professional experience – devskillhub python programming intern completed handson internship focused python programming developed practical coding skills working realworld projects solving algorithmic challenges gained experience core python concepts data structures object oriented programming file handling libraries like numpy pandas collaborated mentors peers write clean efficient well documented code adhered industrystandard best practices •recommended improvements facilitate team project workflow •participated team meetings discuss project progress brainstorm new ideas improving product education – lucknowbtech integral university sgpa cgpa first division skills python programming visualizationdata analysis pandasmachine learning numpy languages hindi english interests solving puzzles brain teasersreading tech blogs articles playing chess strategy based gamesprojects – credit card fraud detection machine learning project python scikit learn pandas matplotlib developed machine learning model detect fraudulent credit card transactions using imbalanced dataset implemented compared multiple algorithms including logistic regression knearest neighbors decision tree random forest xgboost applied data preprocessing techniques handled class imbalance using undersampling evaluated model performance using metrics accuracy precision recall fscore rocauc visualized data distributions model results using histograms confusion matrices built userfriendly frontend using streamlit allow interactive model selection prediction publications integrating credit card fraud detection machine learning irjet journal soft skill effective communication team collaboration adaptability willingness learn time management'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: Load and preprocess CVs\n",
    "\n",
    "cv_folder = \"./data/sample_cvs\"\n",
    "cv_files = glob.glob(os.path.join(cv_folder, \"*.pdf\"))\n",
    "print(f\"Found {len(cv_files)} CV PDF files.\")\n",
    "\n",
    "# Extract and clean CV texts\n",
    "cv_texts = [prepare_document(f, remove_stopwords=True) for f in cv_files]\n",
    "\n",
    "# Parse CVs for structured info\n",
    "parsed_cvs = [parse_cv_text(os.path.basename(f), text) for f, text in zip(cv_files, cv_texts)]\n",
    "\n",
    "print(\"Sample parsed CV data:\")\n",
    "parsed_cvs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736a235c-387b-45bf-8798-dc7af21ecbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 JD text files.\n",
      "Sample parsed JD data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'domain': 'IT',\n",
       " 'degrees': ['BTECH', 'MTECH'],\n",
       " 'skills': ['analysis proficiency sql database management familiarity cloud platforms aws',\n",
       "  'deep learning',\n",
       "  'engineer location bengaluru india experience',\n",
       "  'feature',\n",
       "  'frameworks required skills',\n",
       "  'hyperparameter tuning',\n",
       "  'java',\n",
       "  'large datasets',\n",
       "  'machine learning',\n",
       "  'machine learning models',\n",
       "  'models applications',\n",
       "  'nlp',\n",
       "  'numpy',\n",
       "  'pandas',\n",
       "  'position machine',\n",
       "  'production',\n",
       "  'python',\n",
       "  'pytorch',\n",
       "  'sql',\n",
       "  'techniques collaborate software engineers',\n",
       "  'tensorflow',\n",
       "  'tensorflow pytorch',\n",
       "  'understanding data structures algorithms experience nlp computer vision',\n",
       "  'updated latest advancements',\n",
       "  'years responsibilities design'],\n",
       " 'text': 'position machine learning engineer location bengaluru india experience – years responsibilities design develop deploy machine learning models production work large datasets perform data cleaning preprocessing feature engineering optimize model performance using hyperparameter tuning advanced ml techniques collaborate software engineers integrate ml models applications stay updated latest advancements ml algorithms frameworks required skills strong programming skills python experience pandas numpy scikitlearn tensorflow pytorch good understanding data structures algorithms experience nlp computer vision timeseries analysis proficiency sql database management familiarity cloud platforms aws azure gcp dockerkubernetes education btech mtech computer science data science artificial intelligence related field'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Load and preprocess JDs\n",
    "\n",
    "jd_folder = \"./data/sample_jds\"\n",
    "jd_files = glob.glob(os.path.join(jd_folder, \"*.txt\"))\n",
    "print(f\"Found {len(jd_files)} JD text files.\")\n",
    "\n",
    "jd_texts = [prepare_document(f, remove_stopwords=True) for f in jd_files]\n",
    "parsed_jds = [extract_requirements(text) for text in jd_texts]\n",
    "\n",
    "print(\"Sample parsed JD data:\")\n",
    "parsed_jds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83114daf-60e9-4114-88d0-ad7e10701f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 feedback entries.\n",
      "Sample sentiment results:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Neutral', 0.0),\n",
       " ('Positive', 0.49),\n",
       " ('Neutral', 0.13),\n",
       " ('Neutral', 0.08),\n",
       " ('Positive', 0.46)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Load HR feedbacks and run sentiment classification\n",
    "\n",
    "feedback_file = \"./data/feedbacks.txt\"\n",
    "with open(feedback_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    feedbacks = [line.strip() for line in f if line.strip()]\n",
    "print(f\"Loaded {len(feedbacks)} feedback entries.\")\n",
    "\n",
    "# Classify sentiments\n",
    "feedback_sentiments = [classify_sentiment(fb) for fb in feedbacks]\n",
    "print(\"Sample sentiment results:\")\n",
    "feedback_sentiments[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef377aaa-5eb7-4db4-838d-585ec1ee5567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected JD 1 domain: IT\n",
      "Required degrees: ['BTECH', 'MTECH']\n",
      "Key skills: ['analysis proficiency sql database management familiarity cloud platforms aws', 'deep learning', 'engineer location bengaluru india experience', 'feature', 'frameworks required skills', 'hyperparameter tuning', 'java', 'large datasets', 'machine learning', 'machine learning models'] ...\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Select a JD to evaluate candidates against\n",
    "\n",
    "jd_index = 0  # Change to evaluate other JDs\n",
    "jd_text = jd_texts[jd_index]\n",
    "jd_req = parsed_jds[jd_index]\n",
    "\n",
    "print(f\"Selected JD {jd_index+1} domain: {jd_req['domain']}\")\n",
    "print(f\"Required degrees: {jd_req['degrees']}\")\n",
    "print(f\"Key skills: {jd_req['skills'][:10]} ...\")  # show first 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d2992c-4ea6-49e3-ba44-a8715f5014ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 candidates by adjusted similarity score:\n",
      "cv17 (14).pdf: 0.3668\n",
      "cv1.pdf.pdf: 0.3616\n",
      "cv15.pdf.pdf: 0.2974\n",
      "cv14.pdf.pdf: 0.2954\n",
      "cv12.pdf.pdf: 0.2941\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Compute similarity scores & apply rule-based score enhancement\n",
    "\n",
    "base_sim_scores = compute_similarity(cv_texts, jd_text)\n",
    "adjusted_scores = [rule_based_score(sim, cv_texts[i], jd_req['skills']) for i, sim in enumerate(base_sim_scores)]\n",
    "\n",
    "# Display top 5 scores\n",
    "top_scores = sorted(zip(cv_files, adjusted_scores), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top 5 candidates by adjusted similarity score:\")\n",
    "for fname, score in top_scores:\n",
    "    print(f\"{os.path.basename(fname)}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ea515e-c061-426c-a0fb-1938147097e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1] → Needs Review | Sim=16.2%, Sentiment=Neutral(0.00), DegreeMatch=True, Skills=24.0%, RL Action=Needs Review, RL Confidence=0%\n",
      "[CV 2] → Reject | ❌ Similarity score below 0.08\n",
      "[CV 3] → Reject | ❌ Similarity score below 0.08\n",
      "[CV 4] → Strong Hire | Sim=9.4%, Sentiment=Neutral(0.08), DegreeMatch=True, Skills=20.0%, RL Action=Strong Hire, RL Confidence=0%\n",
      "[CV 5] → Strong Hire | Sim=10.3%, Sentiment=Positive(0.46), DegreeMatch=True, Skills=12.0%, RL Action=Strong Hire, RL Confidence=0%\n",
      "[CV 6] → Strong Hire | Sim=9.5%, Sentiment=Neutral(0.32), DegreeMatch=True, Skills=20.0%, RL Action=Strong Hire, RL Confidence=100.0%\n",
      "[CV 7] → Strong Hire | Sim=9.7%, Sentiment=Negative(-0.42), DegreeMatch=True, Skills=20.0%, RL Action=Strong Hire, RL Confidence=0%\n",
      "[CV 8] → Reject | ❌ Similarity score below 0.08\n",
      "[CV 9] → Strong Hire | Sim=11.7%, Sentiment=Negative(-0.48), DegreeMatch=True, Skills=24.0%, RL Action=Strong Hire, RL Confidence=100.0%\n",
      "[CV 10] → Reject | ❌ Similarity score below 0.08\n",
      "[CV 11] → Reject | ❌ Skills match below 10%\n",
      "[CV 12] → Reject | ❌ Skills match below 10%\n",
      "[CV 13] → Strong Hire | Sim=9.3%, Sentiment=Negative(-0.49), DegreeMatch=True, Skills=20.0%, RL Action=Strong Hire, RL Confidence=100.0%\n",
      "[CV 14] → Strong Hire | Sim=8.5%, Sentiment=Neutral(0.00), DegreeMatch=True, Skills=20.0%, RL Action=Strong Hire, RL Confidence=100.0%\n",
      "[CV 15] → Reject | ❌ Similarity score below 0.08\n",
      "[CV 16] → Reject | ❌ Skills match below 10%\n",
      "[CV 17] → Reject | ❌ Similarity score below 0.08\n",
      "[CV 18] → Reject | ❌ Similarity score below 0.08\n",
      "Rewards history: [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_index</th>\n",
       "      <th>similarity_score_%</th>\n",
       "      <th>skill_match_%</th>\n",
       "      <th>degree_match</th>\n",
       "      <th>match_score_%</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>rl_confidence_%</th>\n",
       "      <th>decision</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>46.7</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Needs Review</td>\n",
       "      <td>Sim=16.2%, Sentiment=Neutral(0.00), DegreeMatc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42.5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Reject</td>\n",
       "      <td>❌ Similarity score below 0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>True</td>\n",
       "      <td>41.1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Reject</td>\n",
       "      <td>❌ Similarity score below 0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Strong Hire</td>\n",
       "      <td>Sim=9.4%, Sentiment=Neutral(0.08), DegreeMatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>40.8</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Strong Hire</td>\n",
       "      <td>Sim=10.3%, Sentiment=Positive(0.46), DegreeMat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cv_index  similarity_score_%  skill_match_%  degree_match  match_score_%  \\\n",
       "0         1                16.2           24.0          True           46.7   \n",
       "1         2                 7.5           20.0          True           42.5   \n",
       "2         3                 7.3           16.0          True           41.1   \n",
       "3         4                 9.4           20.0          True           43.1   \n",
       "4         5                10.3           12.0          True           40.8   \n",
       "\n",
       "  sentiment_label  sentiment_score  rl_confidence_%      decision  \\\n",
       "0         Neutral             0.00              0.0  Needs Review   \n",
       "1        Positive             0.49              0.0        Reject   \n",
       "2         Neutral             0.13              0.0        Reject   \n",
       "3         Neutral             0.08              0.0   Strong Hire   \n",
       "4        Positive             0.46              0.0   Strong Hire   \n",
       "\n",
       "                                         explanation  \n",
       "0  Sim=16.2%, Sentiment=Neutral(0.00), DegreeMatc...  \n",
       "1                      ❌ Similarity score below 0.08  \n",
       "2                      ❌ Similarity score below 0.08  \n",
       "3  Sim=9.4%, Sentiment=Neutral(0.08), DegreeMatch...  \n",
       "4  Sim=10.3%, Sentiment=Positive(0.46), DegreeMat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7: Initialize RL Agent and run full decision pipeline\n",
    "\n",
    "actions = [\"Strong Hire\", \"Consider\", \"Needs Review\", \"Reject\"]\n",
    "rl_agent = SimpleRLAgent(actions)\n",
    "\n",
    "similarity_threshold = 0.08\n",
    "skill_match_threshold = 0.1\n",
    "\n",
    "results = make_decision(\n",
    "    cv_texts=cv_texts,\n",
    "    jd_text=jd_text,\n",
    "    feedbacks=feedbacks,\n",
    "    rl_agent=rl_agent,\n",
    "    similarity_threshold=similarity_threshold,\n",
    "    skill_match_threshold=skill_match_threshold\n",
    ")\n",
    "print(\"Rewards history:\", rl_agent.get_reward_history())\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106cf374-2a04-44f4-b239-ecce0c8faa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to final_decisions.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save results to CSV and json\n",
    "def save_results_to_json(results, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "save_results_to_csv(results, filename=\"final_decisions.csv\")\n",
    "save_results_to_json(results, \"final_decisions.json\")\n",
    "print(\"Results saved to final_decisions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6a157-e962-4080-8ca0-2f40a8e05dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Visualization - Match Scores distribution\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(results_df['match_score_%'], bins=20, kde=True)\n",
    "plt.title(\"Distribution of Candidate Match Scores (%)\")\n",
    "plt.xlabel(\"Match Score (%)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8197e9-3bf0-411f-84d4-a0085d4ba935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Visualization - Decision counts\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=results_df, x='decision', order=actions)\n",
    "plt.title(\"Decision Counts by RL Agent\")\n",
    "plt.xlabel(\"Decision\")\n",
    "plt.ylabel(\"Number of Candidates\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e9050-12ca-4238-b817-2a48cf060d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rewards history:\", rl_agent.get_reward_history())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6157d-6de7-4717-a3cd-0b053657cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Visualization - RL Agent Reward History (simulated)\n",
    "\n",
    "# RL Agent rewards recorded during decision making\n",
    "reward_history = rl_agent.get_reward_history()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(reward_history, marker='o', linestyle='-', color='teal')\n",
    "plt.title(\"RL Agent Reward History Over Time\")\n",
    "plt.xlabel(\"Decision Step\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2a619-2bc0-4512-8e06-d2229d9e7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug snippet to check similarity, skills, and RL agent state\n",
    "\n",
    "# 1. Raw similarity scores\n",
    "sim_scores = compute_similarity(cv_texts, jd_text)\n",
    "print(\"\\nRaw similarity scores:\")\n",
    "for i, score in enumerate(sim_scores):\n",
    "    print(f\"CV {i+1}: {score:.4f}\")\n",
    "\n",
    "# 2. Skills from CVs and JD\n",
    "print(\"\\nExtracted skills from first 5 CVs:\")\n",
    "for i in range(min(5, len(cv_texts))):\n",
    "    parsed = parse_cv_text(f\"cv_{i+1}\", cv_texts[i])\n",
    "    print(f\"CV {i+1} skills: {parsed['skills']}\")\n",
    "print(\"JD required skills:\", jd_req['skills'])\n",
    "\n",
    "# 3. Skill bonus check\n",
    "print(\"\\nSkill bonuses and total scores:\")\n",
    "for i in range(len(cv_texts)):\n",
    "    bonus = 0.0\n",
    "    for skill in jd_req['skills']:\n",
    "        if skill.lower() in cv_texts[i].lower():\n",
    "            bonus += 0.05\n",
    "    total = min(sim_scores[i] + bonus, 1.0)\n",
    "    print(f\"CV {i+1}: base={sim_scores[i]:.4f}, bonus={bonus:.4f}, total={total:.4f}\")\n",
    "\n",
    "# 4. RL agent Q-table snapshot\n",
    "print(\"\\nRL agent Q-table snapshot:\")\n",
    "rl_agent.print_q_table()\n",
    "\n",
    "# 5. Thresholds for decision\n",
    "print(f\"\\nCurrent thresholds: similarity={similarity_threshold}, skill match={skill_match_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccd185-5aba-439b-8462-6321cc881258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
